{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Traffic Sign Recognition** \n",
    "\n",
    "## P2 Writeup\n",
    "\n",
    "---\n",
    "\n",
    "### **Build a Traffic Sign Recognition Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Load the data set (see below for links to the project data set)\n",
    "* Explore, summarize and visualize the data set\n",
    "* Design, train and test a model architecture\n",
    "* Use the model to make predictions on new images\n",
    "* Analyze the softmax probabilities of the new images\n",
    "* Summarize the results with a written report\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    " <img src=\"./examples/visualization.jpg\" /><p style=\"text-align: center;\"> Visualization </p>\n",
    " <img src=\"./examples/grayscale.jpg\" /><p style=\"text-align: center;\"> Grayscaling </p> \n",
    " <img src=\"./examples/random_noise.jpg \" /><p style=\"text-align: center;\"> Random Noise </p> \n",
    " <img src=\"./examples/placeholder.png \" /><p style=\"text-align: center;\"> Traffic Sign 1 </p> \n",
    " \n",
    " \n",
    "\n",
    "## Rubric Points\n",
    "\n",
    "---\n",
    "### File included\n",
    "- jupyter notebook of the code implementation, and pdf version as well\n",
    "- images visualization and dataset for training, validation, and testing, \n",
    "- checkpoints of saved sessions for trained weight and bias, \n",
    "- new dataset for extra testing, etc\n",
    "- accuracy hanging between high 80 to low 90%\n",
    "\n",
    "Codes and files are uploaded to my github [CarND Project 2 page](https://github.com/chriskcheung/carnd_p2_traffic_sign_classifier/upload)\n",
    "\n",
    "\n",
    "\n",
    "### Data Set Summary & Exploration\n",
    "\n",
    "#### 1. Dataset used for training/validation/testing were provided. I used the numpy library to calculate the following summary statistics of the traffic signs data set:\n",
    "\n",
    "    Number of training examples = 34799\n",
    "    Number of validation examples = 12630\n",
    "    Number of testing examples = 12630\n",
    "    Image data shape = [32, 32, 3]\n",
    "    Number of classes = 43\n",
    "\n",
    "#### 2. Visualization of the dataset\n",
    "\n",
    "Using random number function, I randomly printed out few exploratory visualization of the dataset to illustrate the images to make sure the dataset looked correct.\n",
    "\n",
    " <img src=\"./writeup images/class10.png\" /><p style=\"text-align: center;\"> 10 </p>\n",
    " <img src=\"./writeup images/class10gray.png\" /><p style=\"text-align: center;\"> 10 in Grayscale </p>\n",
    "\n",
    "\n",
    "\n",
    "### Design and Test a Model Architecture\n",
    "\n",
    "#### 1. Preprocessing data\n",
    "\n",
    "At the beginning, I took the advise to normalized the data by using (x-128)/128. It seemed the dataset doesn't work well with 128. The result was not desirable and logits were far off from matching any class. So I decdied to use x/256 to normailze the training data to between 0 and 1. This worked well as and results started showing some matching images at least. I would explained this in the later section. I could have improve the preprocessing by turning the data to gray scale by squeezing the 3 color channel into 1. But given the result seemed to be acceptable, I stopped doing so. \n",
    "\n",
    "#### 2. Model architecture\n",
    "\n",
    "Taking the advise from the project instructure, I started reusing the CNN model from lab and enhanced it for my final model. Below listed the layers involved in my traning model:\n",
    "\n",
    "| 1st Layer        \t\t|     Description\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| Input         \t\t| 32x32x3 RGB image   \t\t\t\t\t\t\t| \n",
    "| Convolution 5x5     \t| 1x1 stride, valid padding, outputs 32x32x6    |\n",
    "| Add bias              | bias1 size of 6                               |\n",
    "| RELU\t\t\t\t\t| \t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Dropout\t\t\t\t| 30%\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 14x14x6  \t\t\t\t|\n",
    "| Convolution 5x5\t    | 1x1 stride, valid padding, outputs 10x10x16   |\n",
    "| Add bias              | bias2 size of 16                              |\n",
    "| RELU\t\t\t\t\t| \t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Dropout\t\t\t\t| 30%\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 5x5x16  \t\t    \t\t|\n",
    "| Flatten               | from 5x5x6 to outputs 400                     |\n",
    "| Fully connected\t\t| flat x weight3 + bias3, outputs 120           |\n",
    "| RELU\t\t\t\t\t| \t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Dropout\t\t\t\t| 30%\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Fully connected\t\t| flat x weight4 + bias4, outputs 84            |\n",
    "| RELU\t\t\t\t\t| \t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Dropout\t\t\t\t| 30%\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Fully connected(logits)| flat x weight5 + bias5, outputs 43           |\n",
    "| Softmax cross entropy | 43 classes of probability distribution    \t|\n",
    "| Reduce mean\t\t\t| \t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    " \n",
    "\n",
    "#### 3. Training Model\n",
    "\n",
    "To train the model, I started with the following hyperparameters:\n",
    "\n",
    "    epochs = 10\n",
    "    batch_size = 256\n",
    "    learning rate = 0.1\n",
    "    conv1 output size = 6\n",
    "    conv2 output size = 16\n",
    "    flatten output size = 120\n",
    "    fullcon1 output size = 400\n",
    "    fullcon2 output size = 84\n",
    "    logits output size = 43\n",
    "    training accuracy = mid 50% \n",
    "\n",
    "Without any improvement to the LeNet model from the Lab, the accuracy rised very slow from 0.21ish with less than 10% increase from each epochs and accuracy seemed to saturated around 0.5ish without being able to climb more. \n",
    "\n",
    "\n",
    "\n",
    "#### 4. Model architecture approach taken\n",
    "\n",
    "At the beginning, I was taking the trial and error approach by plugging in different setting from high to low and observed results before fine tuning the model. First, I adjusted both my learning_rate and batch_size by increasing and decereasing the setting. Increasing the setting didn't seem to improve the accurracy but increased the traing time  due to larger dataset to feed to the model. When I decreased the setting, it started to show improvement. As a result, I tuned down the parameters to let the model learn slower with smaller batch and the accurracy started to climb. With only 10 epochs, the accurracy is hanging around mid 80%. I need to increase epochs from 10 to 20 to get enough of data to train the model in order to get to high 80% to 90%. \n",
    "\n",
    "    My model setting at the begining is:\n",
    "    epochs = 20\n",
    "    batch_size 64\n",
    "    learning rate = 0.001\n",
    "    conv1 output size = 6\n",
    "    conv2 output size = 16\n",
    "    flatten output size = 120\n",
    "    fullcon1 output size = 400\n",
    "    fullcon2 output size = 84\n",
    "    logits output size = 43\n",
    "    training accuracy = 87-91% \n",
    "\n",
    "As I started working on feeding new images to the model, I noticed that some classes higher chance to be able to classify than the other, which led me to question about the dataset that was provided for training. I used a simple numpy.unique function on the label y_train. Turned out that some classes had multiple times higher sample count than the others. \n",
    "\n",
    "    index,counts = np.unique(y_train, return_counts=True)\n",
    "    print(index, \"\\n\", counts)\n",
    "    [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
    "     25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42] \n",
    "     [ 180 1980 2010 1260 1770 1650  360 1290 1260 1320 1800 1170 1890 1920  690\n",
    "      540  360  990 1080  180  300  270  330  450  240 1350  540  210  480  240\n",
    "      390  690  210  599  360 1080  330  180 1860  270  300  210  210]\n",
    "  \n",
    "which means the model was not getting a fair training on some images and may mistaken an image to wrong class. As a result, I went back to the model and added dropout layer to each convulate layer and fully connected layer.\n",
    "\n",
    "I started with 5% dropout, keep_prob = 0.95, the improvement was not significant. Then I swipe throught the keep_prob from 0.95 down to 0.5 to observe the result. Accurracy started to turn around from its highest point around 30% dropour rate, or keep_prob = 0.7. As a result, I settled to 0.7 keep_prob.\n",
    "\n",
    "    My model setting at this round is:\n",
    "    epochs = 20\n",
    "    batch_size 64\n",
    "    learning rate = 0.001\n",
    "    keep_prob = 0.7\n",
    "    conv1 output size = 6\n",
    "    conv2 output size = 16\n",
    "    flatten output size = 120\n",
    "    fullcon1 output size = 400\n",
    "    fullcon2 output size = 84\n",
    "    logits output size = 43\n",
    "    training accuracy = high 80% to low 90%. \n",
    "\n",
    "Another improvement I did was to increase the depth of convulation and fully connected layer. I started with a small depth on each layer as mentioned above, i.e. started at 6 followed by 16, 120, 84, then 43 at outputs. One thing to watch out, as I increased the depth of each layer, the training time increased by exponentially, but accurracy improved by few percentage to low 90% within 10 epochs. It washed out the longer training time as few epochs was needed to reach the 90% accurracy. \n",
    "\n",
    "    My model setting at this round is:\n",
    "    epochs = 2\n",
    "    batch_size 64\n",
    "    learning rate = 0.1\n",
    "    conv1 output size = 64\n",
    "    conv2 output size = 128\n",
    "    flatten output size = 3200\n",
    "    fullcon1 output size = 256\n",
    "    fullcon2 output size = 84\n",
    "    logits output size = 43\n",
    "    traing accuracy = 91.2%\n",
    "\n",
    "With 91.2% accuracy, it is still not enough to meeting the project requirement. I went back to the preprocessing step and took the advise from the project instruction to add one more step on top of the normalization. I turned the training dateset into grayscale using a function called rgb2gray(), by dot producting the 3 color channels array with a preset array [[0.299], [0.587], [0.144]].\n",
    "\n",
    "    def rgb2gray(x):\n",
    "        return np.dot(x, [[0.299], [0.587], [0.144]])\n",
    "\n",
    "This dot product turned the training dataset from shape of 34799x32x32x3 to 34799x32x32x1.After updating the rest of the model to compliant with the modified shape, the training seemed to work much better, and reached 94.2% accuracy. \n",
    "\n",
    "    My final model setting is:\n",
    "    epochs = 2\n",
    "    batch_size 64\n",
    "    learning rate = 0.1\n",
    "    conv1 output size = 64\n",
    "    conv2 output size = 128\n",
    "    flatten output size = 3200\n",
    "    fullcon1 output size = 256\n",
    "    fullcon2 output size = 84\n",
    "    logits output size = 43\n",
    "    traing accuracy = 94.2%\n",
    "\n",
    "After hitting 94.2% accuracy, it is time to stop and continue with the remaining project.\n",
    "\n",
    "\n",
    "\n",
    "### Test Model on New Images\n",
    "\n",
    "I downloaded additional German traffic signs from the link provided below.\n",
    "\n",
    "    [] (http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset)\n",
    "\n",
    "Instead of 5 I downloaded about 100 and picked 20 of them for testing my model. Here are the German traffic signs used:\n",
    "\n",
    " <img src=\"./writeup images/new images.png\" />\n",
    "\n",
    "The first 11 images mixed with low light conditions and shares the same outter shape, color and common letters with one digit in different, which might be difficult to classify from each other. Especially the early version of the model that had not added with grayscaling the image for training, there were only 2 to 3 out of 20 were able to be classified. Accuray was as low as 10%. With grayscaling the tranining dataset and this 20 tests images, it helped brought out the sign even under low light condition which provide the model the advantage to match the image. \n",
    "\n",
    "#### Model predictions vs results\n",
    "\n",
    "Here are the results of the prediction with the final version of my model that had grayscaling support:\n",
    "\n",
    "    prediction   :  [1  2  5  8  16  13  19  12  7  4  10  14  17  15  18  0  9  11  6  3]\n",
    "    class image  :  [1, 2, 5, 8, 16, 13, 19, 12, 7, 4, 10, 14, 17, 15, 18, 0, 9, 11, 6, 3]\n",
    "\n",
    "|\tID\t|\tImage\t\t\t        |     Prediction\t        \t\t\t\t\t| \n",
    "|:-----:|:-------------------------:|:---------------------------------------------:| \n",
    "|\t 1\t| 30 km/h \t    \t\t\t| 30 km/h \t\t\t\t\t\t\t\t\t\t|\n",
    "|\t 2\t| 50 km/h \t    \t\t\t| 50 km/h \t\t\t\t\t\t\t\t\t\t|\n",
    "|\t 5\t| 80 km/h \t    \t\t\t| 80 km/h \t\t\t\t\t\t\t\t\t\t|\n",
    "|\t 8\t| 120 km/h \t    \t\t\t| 120 km/h \t\t\t\t\t\t\t\t\t\t|\n",
    "|\t16\t| Vehicles over 3.5 tons prohibited\t| Vehicles over 3.5 tons prohibited\t\t|\n",
    "|\t13\t| Yield\t\t\t\t\t\t| Yield\t\t\t\t\t\t\t\t\t\t\t|\n",
    "|\t19\t| Dangerous curve on the left\t| Dangerous curve on the left\t\t\t\t|\n",
    "|\t12\t| Priority Road   \t\t\t| Prority Road \t\t\t\t\t\t\t\t\t|\n",
    "|\t 7\t| 100 km/h\t    \t  \t\t| 100 km/h\t\t\t\t\t\t \t\t\t\t|\n",
    "|\t 4\t| 70 km/h \t    \t\t\t| 70 km/h \t\t\t\t\t\t\t\t\t\t|\n",
    "|\t10\t| No passing 3.5 tons vehicle\t| No passing 3.5 tons vehicle\t\t\t\t|\n",
    "|\t14\t| Stop Sign\t\t\t\t\t| Stop sign   \t\t\t\t\t\t\t\t\t| \n",
    "|\t17\t| No entry \t    \t\t\t| No entry \t\t\t\t\t\t\t\t\t\t|\n",
    "|\t15\t| No vehicle\t\t\t\t| No vehicle   \t\t\t\t\t\t\t\t\t| \n",
    "|\t18\t| General caution\t\t\t| General caution      \t\t\t\t\t\t\t|\n",
    "|\t 0\t| 20 km/h\t\t\t\t\t| 20km/h      \t\t\t\t\t\t\t\t\t|\n",
    "|\t 9\t| No passing\t\t\t\t| No passing      \t\t\t\t\t\t\t\t|\n",
    "|\t11\t| Right-of-way next intersection| Right-of-way next intersection\t\t\t|\n",
    "|\t 6\t| End of 80km/h\t\t\t\t| End of 80km/h      \t\t\t\t\t\t\t|\n",
    "|\t 3\t| 60 km/h\t\t\t\t\t| 60 km/h \t\t     \t\t\t\t\t\t\t|\n",
    "\n",
    "The model was able to correctly guess all 20 traffic signs, which gives an accuracy of 100%. \n",
    "\n",
    "\n",
    "#### Prediction on each of the five new images by softmax probabilities\n",
    "\n",
    "Provide the top 5 softmax probabilities for each image along with the sign type of each probability. \n",
    "The code for making predictions on my final model is located in the 11th cell of the Ipython notebook.\n",
    "\n",
    "For the first image, the model is relatively sure that this is a 80 km/h speed limit sign (probability of 2.576e-12 in scale of 43 classes). The top five soft max probabilities were\n",
    "\n",
    "| Probability         \t|     Prediction\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| 2.47635181e-12    \t| 80 km/h   \t\t\t\t\t\t\t\t\t| \n",
    "| 1.64791090e-14    \t| 60 km/h \t\t\t\t\t\t\t\t\t\t|\n",
    "| 4.87679537e-16\t\t| 50 km/h\t\t\t\t\t\t\t\t\t\t|\n",
    "| 4.27841437e-17\t\t| No passing for 3.5 tons vehicle\t\t\t\t|\n",
    "| 1.39092786e-17\t    | 120 km/h      \t\t\t\t\t\t\t\t|\n",
    "\n",
    "\n",
    "For the second image, the model is relatively sure that this is a Vehicles over 3.5 tons prohibited speed limit sign (probability of 2.576e-12 in scale of 43 classes). The top five soft max probabilities were\n",
    "\n",
    "| Probability         \t|     Prediction\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| 6.15605078e-09\t\t| Vehicles over 3.5 tons prohibited   \t\t\t|\n",
    "| 6.51597300e-16    \t| 80 km/h \t\t\t\t\t\t\t\t\t\t|\n",
    "| 3.04514538e-16\t\t| 50 km/h\t\t\t\t\t\t\t\t\t\t|\n",
    "| 1.26701716e-16\t\t| Roundabout mandatory\t\t\t\t\t\t\t|\n",
    "| 8.67156994e-17\t\t| 60 km/h      \t\t\t\t\t\t\t\t\t|\n",
    "\n",
    "\n",
    "For the thrid image, the model is relatively sure that this is a Yield sign (probability of 6.18758433e-10 in scale of 43 classes). The top five soft max probabilities were\n",
    "\n",
    "| Probability         \t|     Prediction\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| 6.18758433e-10\t\t| Yield   \t\t\t\t\t\t\t\t\t\t| \n",
    "| 5.17210328e-17\t\t| No vehicle\t\t\t\t\t\t\t\t\t|\n",
    "| 5.10849475e-17    \t| Ahead only\t\t\t\t\t\t\t\t\t|\n",
    "| 2.80259909e-17\t\t| Priority road\t\t\t\t\t\t\t\t\t|\n",
    "| 1.62817186e-17 \t    | Keep left      \t\t\t\t\t\t\t\t|\n",
    "\n",
    "\n",
    "For the fourth image, the model is relatively sure that this is a No vehicle sign (probability of 1 in scale of 43 classes). The top five soft max probabilities were\n",
    "\n",
    "| Probability         \t|     Prediction\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| 1\t\t\t\t\t\t| No vehicle\t\t\t\t\t \t\t\t\t|\n",
    "| 5.54273905e-10 \t    | 50 km/h       \t\t\t\t\t\t\t\t|\n",
    "| 3.91470253e-15\t\t| No passing\t\t\t\t\t\t\t\t\t|\n",
    "| 1.56490999e-15 \t    | Keep right      \t\t\t\t\t\t\t\t|\n",
    "| 6.50165867e-16\t\t| Priority road\t\t\t\t\t\t\t\t\t|\n",
    "\n",
    "\n",
    "For the fifth image, the model is relatively sure that this is a 80 km/h speed limit sign (probability of 4.53066438e-14 in scale of 43 classes). The top five soft max probabilities were\n",
    "\n",
    "| Probability         \t|     Prediction\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| 4.53066438e-14\t\t| 30 km/h\t\t\t\t\t\t\t\t\t\t|\n",
    "| 3.39941612e-16 \t    | 50 km/h      \t\t\t\t\t\t\t\t\t|\n",
    "| 1.51703826e-16\t\t| 20 km/h\t\t\t\t\t\t\t\t\t\t|\n",
    "| 3.69844595e-17 \t    | Keep right      \t\t\t\t\t\t\t\t|\n",
    "| 2.00030834e-17\t\t| 70 km/h\t\t\t\t\t\t\t\t\t\t|\n",
    "\n",
    "          \n",
    "### (Optional) Visualizing the Neural Network (See Step 4 of the Ipython notebook for more details)\n",
    "####1. Discuss the visual output of your trained network's feature maps. What characteristics did the neural network use to make classifications?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
